{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e5a2504",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2be5faac",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1   \n",
    "gamma = 0.9   \n",
    "epsilon = 0.1  \n",
    "num_episodes = 1000\n",
    "num_states = 4  \n",
    "num_actions = 4  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3cb803d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = np.array([\n",
    "    [-1, -1, -1, 0],   \n",
    "    [-1, -1, -1, 10],  \n",
    "    [-1, -1, -1, -1],  \n",
    "    [0, 10, -1, -1]    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d12f48b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.zeros((num_states, num_actions))\n",
    "V = np.zeros(num_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "784dee37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(state):\n",
    "    if random.uniform(0, 1) < epsilon:\n",
    "        return random.randint(0, num_actions - 1)  \n",
    "    else:\n",
    "        return np.argmax(Q[state])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46bf3619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition(state, action):\n",
    "    next_state = action\n",
    "    reward = rewards[state, action]\n",
    "    return next_state, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a46828a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plain_q_learning():\n",
    "    for episode in range(num_episodes):\n",
    "        state = random.randint(0, num_states - 1)\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = select_action(state)\n",
    "            next_state, reward = transition(state, action)\n",
    "            Q[state, action] += alpha * (reward + gamma * np.max(Q[next_state]) - Q[state, action])\n",
    "            state = next_state\n",
    "            if reward == 10:  \n",
    "                done = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "519aaf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def td_0():\n",
    "    for episode in range(num_episodes):\n",
    "        state = random.randint(0, num_states - 1)\n",
    "        done = False\n",
    "        while not done:\n",
    "            next_state, reward = transition(state, select_action(state))\n",
    "            V[state] += alpha * (reward + gamma * V[next_state] - V[state])\n",
    "            state = next_state\n",
    "            if reward == 10:\n",
    "                done = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "126dc120",
   "metadata": {},
   "outputs": [],
   "source": [
    "def td_2():\n",
    "    n = 2  \n",
    "    for episode in range(num_episodes):\n",
    "        states = [random.randint(0, num_states - 1)]\n",
    "        rewards_episode = []\n",
    "        T = float('inf')\n",
    "        t = 0\n",
    "        while True:\n",
    "            if t < T:\n",
    "                action = select_action(states[-1])\n",
    "                next_state, reward = transition(states[-1], action)\n",
    "                states.append(next_state)\n",
    "                rewards_episode.append(reward)\n",
    "                if reward == 10:\n",
    "                    T = t + 1\n",
    "\n",
    "            tau = t - n + 1\n",
    "            if tau >= 0:\n",
    "                G = sum([gamma ** (i - tau - 1) * rewards_episode[i] for i in range(tau + 1, min(t + 1, T))])\n",
    "                if tau + n < T:\n",
    "                    G += gamma ** n * V[states[tau + n]]\n",
    "                V[states[tau]] += alpha * (G - V[states[tau]])\n",
    "\n",
    "            if tau == T - 1:\n",
    "                break\n",
    "            t += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d947966d",
   "metadata": {},
   "source": [
    "Q-Learning with TD(0) and TD(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93be48e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_learning_td_0():\n",
    "    for episode in range(num_episodes):\n",
    "        state = random.randint(0, num_states - 1)\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = select_action(state)\n",
    "            next_state, reward = transition(state, action)\n",
    "            Q[state, action] += alpha * (reward + gamma * np.max(Q[next_state]) - Q[state, action])\n",
    "            V[state] += alpha * (reward + gamma * V[next_state] - V[state])\n",
    "            state = next_state\n",
    "            if reward == 10:\n",
    "                done = True\n",
    "                \n",
    "def q_learning_td_2():\n",
    "    n = 2  # Step size\n",
    "    for episode in range(num_episodes):\n",
    "        states = [random.randint(0, num_states - 1)]\n",
    "        rewards_episode = []\n",
    "        T = float('inf')\n",
    "        t = 0\n",
    "        while True:\n",
    "            if t < T:\n",
    "                action = select_action(states[-1])\n",
    "                next_state, reward = transition(states[-1], action)\n",
    "                states.append(next_state)\n",
    "                rewards_episode.append(reward)\n",
    "                if reward == 10:\n",
    "                    T = t + 1\n",
    "            tau = t - n + 1\n",
    "            if tau >= 0:\n",
    "                G = sum([gamma ** (i - tau - 1) * rewards_episode[i] for i in range(tau + 1, min(t + 1, T))])\n",
    "                if tau + n < T:\n",
    "                    G += gamma ** n * V[states[tau + n]]\n",
    "                V[states[tau]] += alpha * (G - V[states[tau]])\n",
    "                Q[states[tau], select_action(states[tau])] += alpha * (G - Q[states[tau], select_action(states[tau])])\n",
    "\n",
    "            if tau == T - 1:\n",
    "                break\n",
    "            t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c516068f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_q_learning()\n",
    "td_0()\n",
    "td_2()\n",
    "q_learning_td_0()\n",
    "q_learning_td_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2bf871c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q-Table:\n",
      "[[ 0.26937118  7.25793423 -0.74170404  2.7240472 ]\n",
      " [-0.25538632 -0.47348198 -0.23489449  0.75495003]\n",
      " [ 4.65454301  2.87573562  2.9833503   9.37319862]\n",
      " [-0.33655333  0.17625129 -0.44315168 -0.57413625]]\n",
      "\n",
      "Value Function V:\n",
      "[6.74602925 0.55679944 9.54334251 0.11177618]\n"
     ]
    }
   ],
   "source": [
    "print(\"Q-Table:\")\n",
    "print(Q)\n",
    "print(\"\\nValue Function V:\")\n",
    "print(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb015ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
